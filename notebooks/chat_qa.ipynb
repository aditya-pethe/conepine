{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.callbacks.base import CallbackManager\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# from transcript_search import search_transcript\n",
    "import pinecone\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX = os.getenv(\"PINECONE_INDEX\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_ENV,  # next to api key in console\n",
    "    )\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "embed = OpenAIEmbeddings(\n",
    "        model='text-embedding-ada-002',\n",
    "        openai_api_key=OPENAI_API_KEY\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import urllib\n",
    "from youtube_transcript_api.formatters import TextFormatter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "def get_video_from_url(video_url):\n",
    "\n",
    "    parsed_url = urllib.parse.urlparse(video_url)\n",
    "    query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "    video_id = query_params[\"v\"][0]\n",
    "\n",
    "    return YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "def preprocess_transcript(transcript):\n",
    "    \n",
    "    formatter = TextFormatter()\n",
    "    formatted_transcript = formatter.format_transcript(transcript).replace(\"\\n\", \" \")\n",
    "\n",
    "    return formatted_transcript\n",
    "\n",
    "\n",
    "# chunk by an arbitrary chunk size - a potential improvement is using spacy or NLTK as the splitter\n",
    "def chunk_by_text(text, chunk_size = 500, chunk_overlap = 20):\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap  = chunk_overlap\n",
    "    )\n",
    "\n",
    "    docs = []  # List holding all the documents\n",
    "\n",
    "    for i,chunk in enumerate(text_splitter.split_text(text)):\n",
    "        # Generate documents\n",
    "        string_index = i * (chunk_size - chunk_overlap)\n",
    "\n",
    "        docs.append(Document(\n",
    "            page_content=chunk\n",
    "            )) \n",
    "\n",
    "    return docs\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=jSP-gSEyVeI\"\n",
    "ts = get_video_from_url(url)\n",
    "formatted_transcript = preprocess_transcript(ts)\n",
    "docs = chunk_by_text(formatted_transcript)\n",
    "docs[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Document(page_content=\"large language models are incredibly powerful as we've seen but they lack some of the abilities that even the dumbest computer programs can handle with ease logic calculations and search are just a few examples of where large language models fail and really dumb computer programs um can actually perform very well we've been using computers to solve incredibly complex calculations for a very long time yet if we ask gbt4 to tell us the answer to what is 4.1 multiplied by 7.9 it actually fails\", metadata={})"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "docsearch = Pinecone.from_existing_index(PINECONE_INDEX, OpenAIEmbeddings())\n",
    "# docsearch = FAISS.from_documents(docs, OpenAIEmbeddings)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(chat, chain_type=\"stuff\", retriever=docsearch.as_retriever())\n",
    "query = \"How do you intialize an agent in langchain\"\n",
    "qa.run(query)\n",
    "\n",
    "# docsearch.similarity_search(\"How do I create an agent in langchain\")\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'To initialize an agent in Lang chain, you need to have three key components: a large language model or multiple large language models, a tool that you will be interacting with, and an agent to control the interaction. You can use agents with several other tools, and you can create your own agent. To initialize the language model, you first need to initialize your OpenAI LM, and then you can define the agent by giving it a name, a description of when it should be used, and the function it should run. Different types of agents can be used in Lang chain depending on the task you want to accomplish.'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.11.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.11.3 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}